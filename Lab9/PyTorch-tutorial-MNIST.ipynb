{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tensor-Reloaded/Neural-Networks-Template-2024/blob/main/Lab09/PyTorch-tutorial-MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0gJwp5pFjqr"
      },
      "source": [
        "## Datasets in PyTorch\n",
        "\n",
        "https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU83eW5DEWKF",
        "outputId": "82664cbd-b486-4a82-faf7-40818874dc59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "('apple', 'fruit')\n",
            "apple fruit\n",
            "cucumber vegetable\n",
            "pear fruit\n",
            "orange fruit\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# A dataset in PyTorch should implement the following methods:\n",
        "# __len__ (optional in some rare cases) and __getitem__ (mandatory)\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # In __getitem__ we usually load the data from the disk or from memory, apply transformations and return it\n",
        "        return self.data[i], self.labels[i]\n",
        "\n",
        "\n",
        "dataset = SimpleDataset(data=[\"apple\", \"cucumber\", \"pear\", \"orange\"],\n",
        "                        labels=[\"fruit\", \"vegetable\", \"fruit\", \"fruit\"])\n",
        "print(len(dataset))  # uses SimpleDataset.__len__\n",
        "print(dataset[0])  # uses SimpleDataset.__getitem__\n",
        "\n",
        "for data, label in dataset:\n",
        "    print(data, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQz5Fyn3F3TO"
      },
      "source": [
        "## DataLoaders in PyTorch\n",
        "\n",
        "https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgbkDt4DGDah",
        "outputId": "a836d430-337a-43bc-e0d0-92e4ddda0c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "('orange', 'apple') ('fruit', 'fruit')\n",
            "('pear', 'cucumber') ('fruit', 'vegetable')\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# We use DataLoaders to automatically load and batchify the data from the Dataset\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "print(len(dataloader))\n",
        "for data_batched, labels_batched in dataloader:\n",
        "    print(data_batched, labels_batched)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oNaU-G2GfBI",
        "outputId": "ae2edf1e-9a32-468a-d62b-20e8cfc24b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "('pear', 'apple', 'orange') ('fruit', 'fruit', 'fruit')\n",
            "('cucumber',) ('vegetable',)\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
        "# If the batch size does not divide the size of the dataset, the size of the last batch will be len(dataset) % batch_size\n",
        "\n",
        "print(len(dataloader))\n",
        "for data_batched, labels_batched in dataloader:\n",
        "    print(data_batched, labels_batched)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-FrnB-DGiX-",
        "outputId": "a4ac39b9-e8fb-49b3-ce59-178b4730e17c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "('apple', 'cucumber', 'orange') ('fruit', 'vegetable', 'fruit')\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=3, shuffle=True, drop_last=True)\n",
        "# We can drop the last batch\n",
        "\n",
        "print(len(dataloader))\n",
        "for data_batched, labels_batched in dataloader:\n",
        "    print(data_batched, labels_batched)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svccAuziHFqe"
      },
      "source": [
        "Also see https://pytorch.org/tutorials/beginner/basics/data_tutorial.html.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Mt8IigHHgw"
      },
      "source": [
        "## Defining a model in PyTorch\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8AfJN-1HTFS",
        "outputId": "0a4d4db5-382c-4326-ae3d-2731367ae5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (layer_1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (layer_2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        # We call the constructor of the parent module\n",
        "        self.layer_1 = nn.Linear(input_size, hidden_size)\n",
        "        # We create a Linear layer: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "        self.layer_2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    # In PyTorch we define only the forward step. The backward step is automatically calculated by the Autograd engine.\n",
        "    def forward(self, x: Tensor):\n",
        "        # x is a Tensor of size [batch size, input_size]\n",
        "        x = self.layer_1(x) # x is a Tensor of size [batch size, hidden_size]\n",
        "        x = x.relu()  # We can use any activation function\n",
        "        x = self.layer_2(x) # x is a Tensor of size [batch size, output_size]\n",
        "        return x\n",
        "\n",
        "\n",
        "model = MyModel(input_size=784, hidden_size=100, output_size=10)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z19V-ldoKRTu"
      },
      "source": [
        "## Devices\n",
        "\n",
        "https://pytorch.org/docs/stable/tensor_attributes.html#torch-device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcAwSZlRJhvy",
        "outputId": "a2ae72d7-d884-485b-a7af-eaea3188a3ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')  # On multi-gpu workstation we can select cuda:0, cuda:1, ...\n",
        "    if torch.mps.is_available():\n",
        "        return torch.device('mps')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "\n",
        "device = get_device()\n",
        "print(device)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYvvsbNlKcGs"
      },
      "source": [
        "## Optimizers in PyTorch\n",
        "\n",
        "https://pytorch.org/docs/main/optim.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3pPM2ORHKEl-"
      },
      "outputs": [],
      "source": [
        "# Optimizers apply the gradients calculated by the Autograd engine to the weights, using their own optimization technique\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True, weight_decay=0.001)  # SGD with Nesterov momentum and weight decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)  # Adam with Weight Decay\n",
        "\n",
        "\n",
        "# Schedulers change the learning rate enabling faster training\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Learning rate scheduler, halves the learning rate each 10 steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mooi-98UMA8j"
      },
      "source": [
        "## Loss functions in PyTorch\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HN2qI2KTMDSk"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()  # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ONsVk_dMaCH"
      },
      "source": [
        "## Training in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gdAjGedQMi3h"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, criterion, optimizer, device):\n",
        "    model.train()  # We need to activate the dropout & batch norm layers\n",
        "\n",
        "    mean_loss = 0.0\n",
        "\n",
        "    for data, labels in train_dataloader:\n",
        "        data = data.to(device)  # We move the data to device. Bonus: we can do this in an async manner using non_blocking and pin_memory\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(data)  # the forward pass\n",
        "        loss = criterion(outputs, labels)  # we calculate the loss\n",
        "\n",
        "        loss.backward()  # we backpropagate the loss\n",
        "\n",
        "        if False:\n",
        "            # After loss.backward(), the gradients for each weight and bias are calculated and assigned to layer.weight.grad and layer.bias.grad\n",
        "            last_layer_w_grad = model.layer_2.weight.grad\n",
        "            last_layer_b_grad = model.layer_2.bias.grad\n",
        "            print(f\"Last layer gradient: {last_layer_w_grad.shape}\")\n",
        "            print(f\"Last layer gradient: {last_layer_b_grad.shape}\")\n",
        "\n",
        "        optimizer.step()  # we update the weights\n",
        "        optimizer.zero_grad()  # we reset the gradients\n",
        "\n",
        "        mean_loss += loss.item()\n",
        "\n",
        "    mean_loss /= len(train_dataloader)\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feVd7tmEOPLX"
      },
      "source": [
        "## Validation in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XA_o2Do9OOax"
      },
      "outputs": [],
      "source": [
        "def val_1(model, val_dataloader, criterion, device):\n",
        "    model.eval()  # We need to deactivate the dropout & batch norm layers\n",
        "\n",
        "    mean_loss = 0.0\n",
        "\n",
        "    for data, labels in val_dataloader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():  # Context manager that disables Autograd (no gradients need to be calculated during validation)\n",
        "            outputs = model(data)  # the forward pass\n",
        "            loss = criterion(outputs, labels)  # we calculate the loss\n",
        "        # A better context manager is torch.inference_mode(), which also disables version counter for tensors.\n",
        "        # Tensors created without version counter can never be used in a operation that requires gradient.\n",
        "\n",
        "        mean_loss += loss.item()\n",
        "\n",
        "    mean_loss /= len(val_dataloader)\n",
        "    return mean_loss\n",
        "\n",
        "@torch.inference_mode()  # it is better to decorate the method with torch.inference_mode or torch.no_grad\n",
        "def val(model, val_dataloader, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    mean_loss = 0.0\n",
        "\n",
        "    for data, labels in val_dataloader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        mean_loss += loss.item()\n",
        "\n",
        "    mean_loss /= len(val_dataloader)\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_nTz76_PnXe"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "roBRKl9ePpZ2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def main(model, train_dataloader, val_dataloader, criterion, optimizer, device, epochs):\n",
        "    with tqdm(tuple(range(epochs))) as tbar:\n",
        "        for epoch in tbar:\n",
        "            train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
        "            val_loss = val(model, val_dataloader, criterion, device)\n",
        "            scheduler.step()\n",
        "            tbar.set_description(f\"Train loss: {train_loss:.3f} | Val loss: {val_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMpcJcuQQLAF",
        "outputId": "7ef6255e-0a10-4675-e552-2f7220afbdb1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MNIST\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m v2\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torchvision'"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "import numpy as np\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "\n",
        "def transforms():\n",
        "    return lambda x: torch.from_numpy(np.array(x, dtype=np.float32).flatten() / 255)\n",
        "\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transforms())\n",
        "val_dataset = MNIST(root='./data', train=False, download=True, transform=transforms())\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=500, shuffle=False)\n",
        "\n",
        "main(model, train_dataloader, val_dataloader, criterion, optimizer, device, 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMdpcDrzxfKymaiPgmdQwzx",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
