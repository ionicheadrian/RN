{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e4687354",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-06T13:25:56.928110Z",
     "iopub.status.busy": "2025-10-06T13:25:56.927828Z",
     "iopub.status.idle": "2025-10-06T13:25:58.843131Z",
     "shell.execute_reply": "2025-10-06T13:25:58.842272Z"
    },
    "papermill": {
     "duration": 1.920785,
     "end_time": "2025-10-06T13:25:58.844911",
     "exception": false,
     "start_time": "2025-10-06T13:25:56.924126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae562b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T13:25:58.850724Z",
     "iopub.status.busy": "2025-10-06T13:25:58.850288Z",
     "iopub.status.idle": "2025-10-06T13:25:59.377505Z",
     "shell.execute_reply": "2025-10-06T13:25:59.376596Z"
    },
    "papermill": {
     "duration": 0.531726,
     "end_time": "2025-10-06T13:25:59.379165",
     "exception": false,
     "start_time": "2025-10-06T13:25:58.847439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = \"../input/extended_mnist_train.pkl\"\n",
    "test_file = \"../input/extended_mnist_test.pkl\"\n",
    "\n",
    "with open(train_file, \"rb\") as fp:\n",
    "    train = pickle.load(fp)\n",
    "\n",
    "with open(test_file, \"rb\") as fp:\n",
    "    test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "07e26e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T13:25:59.384534Z",
     "iopub.status.busy": "2025-10-06T13:25:59.384192Z",
     "iopub.status.idle": "2025-10-06T13:25:59.479972Z",
     "shell.execute_reply": "2025-10-06T13:25:59.479225Z"
    },
    "papermill": {
     "duration": 0.100101,
     "end_time": "2025-10-06T13:25:59.481530",
     "exception": false,
     "start_time": "2025-10-06T13:25:59.381429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#construim training data-ul + labeling \n",
    "#si le convertim in np arrays pt a folosi avantajele lib numpy(mai ales la operatii intre matrici)\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for image, label in train:\n",
    "    train_data.append(image.flatten())\n",
    "    train_labels.append(label)\n",
    "    \n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5b718357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T13:25:59.487299Z",
     "iopub.status.busy": "2025-10-06T13:25:59.486416Z",
     "iopub.status.idle": "2025-10-06T13:25:59.511635Z",
     "shell.execute_reply": "2025-10-06T13:25:59.510449Z"
    },
    "papermill": {
     "duration": 0.029523,
     "end_time": "2025-10-06T13:25:59.513213",
     "exception": false,
     "start_time": "2025-10-06T13:25:59.483690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#acelasi lucru pentru testing data\n",
    "test_data = []\n",
    "for image, label in test:\n",
    "    test_data.append(image.flatten())\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "\n",
    "#print(f\"date train: {train_data.shape}\")\n",
    "#print(f\"label train: {train_labels.shape}\")\n",
    "#print(f\"date test: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c810112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializarea costurilor si a bias-ului \n",
    "\n",
    "np.random.seed(74)\n",
    "\n",
    "features =784 #(pixeli din poza 28*28)\n",
    "clase = 10 # de la 0 la 9\n",
    "\n",
    "W = np.random.randn(features,clase) * 0.01 # am immultit cu 0.01 ca atunci cand facem folosim softmaxul sa nu avem numere gigantice gen e^150 \n",
    "bias = np.zeros(clase) #aici o sa aiba forma (10,)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "be4832df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(scoruri):\n",
    "    exp_scoruri = np.exp(scoruri - np.max(scoruri, axis=1, keepdims=True))\n",
    "    # returnam practic transformarea din setul de scoruri (Z) intr-un set de probabilitati\n",
    "    # mai exact returneaza cele 10 (0,1,2.....9) probabilitati simultan \n",
    "    return exp_scoruri / np.sum(exp_scoruri, axis=1, keepdims=True) \n",
    "    \n",
    "\n",
    "def one_hot_encode(labels, clase):\n",
    "    #transformam din label in clasels n\n",
    "    # PRACTIC daca noi avem la o instanta label ul 3 noi vom return aun set de n clase (in cazu nostru 10) cv de genu \n",
    "    # 3 -> [0,0,0,1,0,0,0,0,0,0]\n",
    "    m = labels.shape[0]\n",
    "    one_hot = np.zeros((m, clase))\n",
    "    one_hot[np.arange(m), labels] = 1\n",
    "    return one_hot\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true): \n",
    "    #y_pred este predictia modelului (rezulatatul softmax)\n",
    "    #y_true este forma transformata a labelului acelei instante.\n",
    "    #folosim y_true pentru a arata cat de aproape de \"adevar\" este modelul nostru\n",
    "\n",
    "    m = y_pred.shape[0] #nr loturi\n",
    "\n",
    "    epsilon = 1e-10 # ca sa ne asiguram ca indiferent ce y_pred avem logaritmul nu arunca vreo eroare tip log(0)\n",
    "\n",
    "    loss = -np.sum(y_true * np.log(y_pred + epsilon)) / m \n",
    "    return loss\n",
    "\n",
    "def forward_propagation(X, W, bias):\n",
    "    z = np.dot(X, W) + bias\n",
    "    y_pred = softmax(z)\n",
    "    return y_pred\n",
    "\n",
    "def backward_propagation(X, y_pred, y_true, W, b, learning_rate):\n",
    "    m = X.shape[0] # luam numarul de monstre\n",
    "    gradient = y_true - y_pred # am calculat practic cat de mult a gresit modelul pentru fiecare clasa in parte\n",
    "\n",
    "\n",
    "    dW = np.dot(X.T, gradient) / m # am calculat delta W, cam cat de mult a contribuit fiecare pixel din input la procentul de eroare \n",
    "    W_nou = W + learning_rate * dW #updatam noile weight uri (Weightul vechi + pasul + directia pasului)\n",
    "\n",
    "    #aici o sa calculam cat de mult trebuie sa ajustam bias ul (acelasi lucru ca la weights)\n",
    "    db = np.sum(gradient, axis=0) / m\n",
    "    b_nou = b + learning_rate * db\n",
    "\n",
    "    \n",
    "    return W_nou, b_nou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "38948da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T13:25:59.518680Z",
     "iopub.status.busy": "2025-10-06T13:25:59.517953Z",
     "iopub.status.idle": "2025-10-06T13:26:06.988688Z",
     "shell.execute_reply": "2025-10-06T13:26:06.987637Z"
    },
    "papermill": {
     "duration": 7.474884,
     "end_time": "2025-10-06T13:26:06.990180",
     "exception": false,
     "start_time": "2025-10-06T13:25:59.515296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antrenarea perceptorului\n",
      "==========\n",
      "epoca 10/150 cu loss ul; 2.4838 si accuracy: 0.9034 si learning rate 0.0015\n",
      "epoca 20/150 cu loss ul; 2.5153 si accuracy: 0.8093 si learning rate 0.002\n",
      "epoca 30/150 cu loss ul; 2.5516 si accuracy: 0.8794 si learning rate 0.0025\n",
      "epoca 40/150 cu loss ul; 2.4869 si accuracy: 0.8253 si learning rate 0.003\n",
      "epoca 50/150 cu loss ul; 2.5599 si accuracy: 0.8731 si learning rate 0.0035\n",
      "epoca 60/150 cu loss ul; 2.5228 si accuracy: 0.8990 si learning rate 0.004\n",
      "epoca 70/150 cu loss ul; 2.5041 si accuracy: 0.8943 si learning rate 0.0045000000000000005\n",
      "epoca 80/150 cu loss ul; 2.4718 si accuracy: 0.8775 si learning rate 0.005000000000000001\n",
      "epoca 90/150 cu loss ul; 2.4708 si accuracy: 0.8512 si learning rate 0.005500000000000001\n",
      "epoca 100/150 cu loss ul; 2.5283 si accuracy: 0.8770 si learning rate 0.006000000000000002\n",
      "epoca 110/150 cu loss ul; 2.4939 si accuracy: 0.8976 si learning rate 0.006500000000000002\n",
      "epoca 120/150 cu loss ul; 2.4811 si accuracy: 0.8960 si learning rate 0.007000000000000003\n",
      "epoca 130/150 cu loss ul; 2.5474 si accuracy: 0.7953 si learning rate 0.007500000000000003\n",
      "epoca 140/150 cu loss ul; 2.5024 si accuracy: 0.8661 si learning rate 0.008000000000000004\n",
      "epoca 150/150 cu loss ul; 2.5120 si accuracy: 0.8495 si learning rate 0.008500000000000004\n"
     ]
    }
   ],
   "source": [
    "# Hiperparametri\n",
    "learning_rate = 0.001\n",
    "epoci = 150\n",
    "batch_size = 64\n",
    "\n",
    "# Converteste etichetele\n",
    "y_train_one_hot = one_hot_encode(train_labels, clase)\n",
    "\n",
    "print(\"antrenarea perceptorului\")\n",
    "print(\"=\"*10)\n",
    "for epoch in range(epoci):\n",
    "    indices = np.random.permutation(train_data.shape[0])\n",
    "\n",
    "    X_shuffled = train_data[indices]\n",
    "    y_shuffled = y_train_one_hot[indices]\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for i in range(0, train_data.shape[0], batch_size):\n",
    "        X_batch = X_shuffled[i:i+batch_size]\n",
    "        y_batch = y_shuffled[i:i+batch_size]\n",
    "        \n",
    "\n",
    "\n",
    "        #partea de ghicire\n",
    "        y_pred = forward_propagation(X_batch, W, bias)\n",
    "\n",
    "\n",
    "        #partea de verificare\n",
    "        batch_loss = cross_entropy_loss(y_pred, y_batch)\n",
    "        epoch_loss += batch_loss\n",
    "        n_batches += 1\n",
    "        #cumva aici se termina partea de \"invatare\"\n",
    "\n",
    "        #Partea de corectarea \n",
    "        W, bias = backward_propagation(X_batch, y_pred, y_batch, W, bias, learning_rate)\n",
    "    \n",
    "    avg_loss = epoch_loss / n_batches\n",
    "    \n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        learning_rate = learning_rate + 0.0005   \n",
    "        y_train_pred = forward_propagation(train_data, W, bias)\n",
    "        train_predictions = np.argmax(y_train_pred, axis=1)\n",
    "        train_accuracy = np.mean(train_predictions == train_labels)\n",
    "        print(f\"epoca {epoch+1}/{epoci} cu loss ul; {avg_loss:.4f} si accuracy: {train_accuracy:.4f} si learning rate {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a4d95c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T13:26:06.997597Z",
     "iopub.status.busy": "2025-10-06T13:26:06.996543Z",
     "iopub.status.idle": "2025-10-06T13:26:07.048177Z",
     "shell.execute_reply": "2025-10-06T13:26:07.047463Z"
    },
    "papermill": {
     "duration": 0.056718,
     "end_time": "2025-10-06T13:26:07.049784",
     "exception": false,
     "start_time": "2025-10-06T13:26:06.993066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuratetea finala 0.8495\n",
      "predictia [9 4 3 0 2 1 2 9 5 5]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = forward_propagation(train_data, W, bias)\n",
    "train_predictions = np.argmax(y_train_pred, axis=1)\n",
    "train_accuracy = np.mean(train_predictions == train_labels)\n",
    "print(f\"acuratetea finala {train_accuracy:.4f}\")\n",
    "\n",
    "y_test_pred = forward_propagation(test_data, W, bias)\n",
    "test_predictions = np.argmax(y_test_pred, axis=1)\n",
    "print(f\"predictia {test_predictions[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e3d3ecf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T13:26:07.056765Z",
     "iopub.status.busy": "2025-10-06T13:26:07.056424Z",
     "iopub.status.idle": "2025-10-06T13:26:07.101575Z",
     "shell.execute_reply": "2025-10-06T13:26:07.100567Z"
    },
    "papermill": {
     "duration": 0.050341,
     "end_time": "2025-10-06T13:26:07.103224",
     "exception": false,
     "start_time": "2025-10-06T13:26:07.052883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATAAAAAAAAAAAAAAAAAAAAA\n"
     ]
    }
   ],
   "source": [
    "# This is how you prepare a submission for the competition\n",
    "predictions_csv = {\n",
    "    \"ID\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "for i, label in enumerate(test_predictions):\n",
    "    predictions_csv[\"ID\"].append(i)\n",
    "    predictions_csv[\"target\"].append(label)\n",
    "\n",
    "df = pd.DataFrame(predictions_csv)\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"GATAAAAAAAAAAAAAAAAAAAAA\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13767536,
     "sourceId": 115341,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.108977,
   "end_time": "2025-10-06T13:26:07.825612",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-06T13:25:51.716635",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
