{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_file = \"./input/extended_mnist_train.pkl\"\n",
    "test_file = \"./input/extended_mnist_test.pkl\"\n",
    "\n",
    "with open(train_file, \"rb\") as fp:\n",
    "    train = pickle.load(fp)\n",
    "with open(test_file, \"rb\") as fp:\n",
    "    test = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for image, label in train:\n",
    "    train_data.append(image.flatten() / 255.0)\n",
    "    train_labels.append(label)\n",
    "\n",
    "test_data = []\n",
    "for image, label in test:\n",
    "    test_data.append(image.flatten() / 255.0)\n",
    "\n",
    "X_train_full = np.array(train_data)\n",
    "y_train_full = np.array(train_labels)\n",
    "X_test = np.array(test_data)\n",
    "\n",
    "# Split\n",
    "split = int(0.9 * len(X_train_full))\n",
    "X_train = X_train_full[:split]\n",
    "y_train = y_train_full[:split]\n",
    "X_val = X_train_full[split:]\n",
    "y_val = y_train_full[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1.0 - a)\n",
    "\n",
    "def one_hot_encode(y, n_classes=10):\n",
    "    n = len(y)\n",
    "    one_hot = np.zeros((n, n_classes))\n",
    "    one_hot[np.arange(n), y] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def forward(X, W1, b1, W2, b2, dropout_rate=0, training=True):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    dropout_mask = None\n",
    "    if training and dropout_rate > 0:\n",
    "        dropout_mask = (np.random.rand(*a1.shape) > dropout_rate) / (1 - dropout_rate)\n",
    "        a1 = a1 * dropout_mask\n",
    "    \n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    return z1, a1, z2, a2, dropout_mask\n",
    "\n",
    "def backward(X, y, z1, a1, z2, a2, W2, dropout_mask, l2_lambda=0.0001):\n",
    "    m = X.shape[0]\n",
    "    y_one_hot = one_hot_encode(y, 10)\n",
    "    \n",
    "    delta2 = a2 - y_one_hot\n",
    "    dW2 = np.dot(a1.T, delta2) / m + l2_lambda * W2\n",
    "    db2 = np.sum(delta2, axis=0, keepdims=True) / m\n",
    "    \n",
    "    delta1 = np.dot(delta2, W2.T) * sigmoid_derivative(a1)\n",
    "    if dropout_mask is not None:\n",
    "        delta1 = delta1 * dropout_mask\n",
    "    \n",
    "    dW1 = np.dot(X.T, delta1) / m\n",
    "    db1 = np.sum(delta1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def compute_accuracy(X, y, W1, b1, W2, b2):\n",
    "    _, _, _, a2, _ = forward(X, W1, b1, W2, b2, dropout_rate=0, training=False)\n",
    "    predictions = np.argmax(a2, axis=1)\n",
    "    return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 120\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 128     \n",
    "LEARNING_RATE = 0.5\n",
    "DROPOUT_RATE = 0.03\n",
    "L2_LAMBDA = 0.001     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoca   1/60 training acc: 0.9019 val: 0.9233 | lr: 0.5000\n",
      "epoca  11/60 training acc: 0.9565 val: 0.9652 | lr: 0.5000\n",
      "epoca  21/60 training acc: 0.9672 val: 0.9712 | lr: 0.5000\n",
      "epoca  31/60 training acc: 0.9720 val: 0.9730 | lr: 0.5000\n",
      "epoca  41/60 training acc: 0.9755 val: 0.9740 | lr: 0.5000\n",
      "epoca  51/60 training acc: 0.9776 val: 0.9755 | lr: 0.5000\n",
      "epoca  60/60 training acc: 0.9786 val: 0.9755 | lr: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "W1, b1, W2, b2 = initialize_weights(784, HIDDEN_SIZE, 10)\n",
    "\n",
    "n_samples = len(X_train)\n",
    "n_batches = n_samples // BATCH_SIZE\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "lr = LEARNING_RATE\n",
    "best_val_acc = 0\n",
    "patience_counter = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    idx = np.random.permutation(n_samples)\n",
    "    X_shuffled = X_train[idx]\n",
    "    y_shuffled = y_train[idx]\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        \n",
    "        X_batch = X_shuffled[start:end]\n",
    "        y_batch = y_shuffled[start:end]\n",
    "        \n",
    "        z1, a1, z2, a2, dropout_mask = forward(\n",
    "            X_batch, W1, b1, W2, b2, \n",
    "            dropout_rate=DROPOUT_RATE, training=True\n",
    "        )\n",
    "        \n",
    "        dW1, db1, dW2, db2 = backward(\n",
    "            X_batch, y_batch, z1, a1, z2, a2, W2, dropout_mask, L2_LAMBDA\n",
    "        )\n",
    "        \n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == EPOCHS - 1:\n",
    "        train_acc = compute_accuracy(X_train, y_train, W1, b1, W2, b2)\n",
    "        val_acc = compute_accuracy(X_val, y_val, W1, b1, W2, b2)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"epoca {epoch+1:3d}/{EPOCHS} \"\n",
    "              f\"training acc: {train_acc:.4f} val: {val_acc:.4f} | \"\n",
    "              f\"lr: {lr:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 3:\n",
    "                lr *= 0.7\n",
    "                patience_counter = 0\n",
    "                print(f\"Learning rate redus la {lr:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 97.83%\n",
      "vall acc: 97.55%\n",
      "training time 75.52s (1.26min)\n"
     ]
    }
   ],
   "source": [
    "# Final metrics\n",
    "train_acc_final = compute_accuracy(X_train_full, y_train_full, W1, b1, W2, b2)\n",
    "val_acc_final = compute_accuracy(X_val, y_val, W1, b1, W2, b2)\n",
    "print(f\"train acc: {train_acc_final*100:.2f}%\")\n",
    "print(f\"vall acc: {val_acc_final*100:.2f}%\")\n",
    "print(f\"training time {training_time:.2f}s ({training_time/60:.2f}min)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission done\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'ID': range(len(predictions)),\n",
    "    'target': predictions.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
